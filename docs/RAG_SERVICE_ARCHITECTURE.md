# RAG Service æ¶æ„è®¾è®¡æ–‡æ¡£
**ä»“åº“ç®¡ç†ç³»ç»Ÿæ™ºèƒ½åˆ†æã€ç ”ç©¶ã€æŠ¥å‘ŠæœåŠ¡**

---

## ğŸ“‹ ç›®å½•

1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [ç³»ç»Ÿæ¶æ„](#ç³»ç»Ÿæ¶æ„)
3. [æŠ€æœ¯æ ˆé€‰æ‹©](#æŠ€æœ¯æ ˆé€‰æ‹©)
4. [æ•°æ®æµç¨‹](#æ•°æ®æµç¨‹)
5. [å®æ–½é˜¶æ®µ](#å®æ–½é˜¶æ®µ)
6. [è¯¦ç»†è®¾è®¡](#è¯¦ç»†è®¾è®¡)
7. [éƒ¨ç½²æ–¹æ¡ˆ](#éƒ¨ç½²æ–¹æ¡ˆ)
8. [æˆæœ¬ä¼°ç®—](#æˆæœ¬ä¼°ç®—)

---

## ğŸ¯ æ¦‚è¿°

### ä¸šåŠ¡ç›®æ ‡

æ„å»ºä¸€ä¸ªåŸºäº RAG (Retrieval-Augmented Generation) çš„æ™ºèƒ½åˆ†ææœåŠ¡ï¼Œèƒ½å¤Ÿï¼š

- **åˆ†æ**: è‡ªåŠ¨åˆ†æåº“å­˜è¶‹åŠ¿ã€é”€å”®æ¨¡å¼ã€å¼‚å¸¸æ£€æµ‹
- **ç ”ç©¶**: æ·±åº¦æŒ–æ˜ç»é”€å•†è¡Œä¸ºã€äº§å“æ€§èƒ½ã€å¸‚åœºæ´å¯Ÿ
- **æŠ¥å‘Š**: ç”Ÿæˆè‡ªç„¶è¯­è¨€ä¸šåŠ¡æŠ¥å‘Šã€å¯è§†åŒ–å›¾è¡¨ã€å†³ç­–å»ºè®®

### æ ¸å¿ƒèƒ½åŠ›

```
ç”¨æˆ·é—®é¢˜ â†’ RAGæ£€ç´¢ â†’ æ•°æ®åˆ†æ â†’ LLMç”Ÿæˆ â†’ æ™ºèƒ½å›ç­”
```

**ç¤ºä¾‹æŸ¥è¯¢:**
- "ä¸Šä¸ªæœˆé”€å”®é¢ä¸‹é™çš„ä¸»è¦åŸå› æ˜¯ä»€ä¹ˆï¼Ÿ"
- "å“ªäº›äº§å“åº“å­˜å‘¨è½¬ç‡æœ€ä½ï¼Ÿ"
- "ç”Ÿæˆæœ¬å‘¨åº“å­˜é¢„è­¦æŠ¥å‘Š"
- "å¯¹æ¯”Aã€Bä¸¤ä¸ªç»é”€å•†çš„é”€å”®è¡¨ç°"

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       å‰ç«¯ç•Œé¢                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ AIåŠ©æ‰‹   â”‚  â”‚ æŠ¥å‘Šç”Ÿæˆ â”‚  â”‚ æ•°æ®æ´å¯Ÿ â”‚  â”‚ æ™ºèƒ½æœç´¢ â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚            â”‚            â”‚            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    API Gateway (FastAPI) â”‚
        â”‚  /api/v1/ai/query       â”‚
        â”‚  /api/v1/ai/report      â”‚
        â”‚  /api/v1/ai/analyze     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    RAG Orchestrator      â”‚
        â”‚  (ä¸šåŠ¡é€»è¾‘å±‚)             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚  Vector Store   â”‚        â”‚   LLM API   â”‚
â”‚  (å‘é‡æ•°æ®åº“)    â”‚        â”‚  (GPT-4/ç­‰)  â”‚
â”‚                 â”‚        â”‚             â”‚
â”‚ - å†å²æŠ¥å‘Š      â”‚        â”‚ - æ–‡æœ¬ç”Ÿæˆ  â”‚
â”‚ - ä¸šåŠ¡çŸ¥è¯†åº“    â”‚        â”‚ - æ•°æ®åˆ†æ  â”‚
â”‚ - äº§å“æ–‡æ¡£      â”‚        â”‚ - æ¨ç†å†³ç­–  â”‚
â”‚ - å¸¸è§é—®é¢˜      â”‚        â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Embedding Service       â”‚
    â”‚  (æ–‡æœ¬å‘é‡åŒ–)              â”‚
    â”‚  - text-embedding-3-small â”‚
    â”‚  - all-MiniLM-L6-v2       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Knowledge Base           â”‚
    â”‚  (çŸ¥è¯†åº“ç®¡ç†)               â”‚
    â”‚                            â”‚
    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
    â”‚ â”‚  Document Processor    â”‚â”‚
    â”‚ â”‚  - PDFè§£æ             â”‚â”‚
    â”‚ â”‚  - Excelè§£æ           â”‚â”‚
    â”‚ â”‚  - Textåˆ†å—            â”‚â”‚
    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
    â”‚                            â”‚
    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
    â”‚ â”‚  Data Connector        â”‚â”‚
    â”‚ â”‚  - MySQLæ•°æ®åº“         â”‚â”‚
    â”‚ â”‚  - APIæ•°æ®æº           â”‚â”‚
    â”‚ â”‚  - å®æ—¶æŸ¥è¯¢            â”‚â”‚
    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ æŠ€æœ¯æ ˆé€‰æ‹©

### åç«¯æŠ€æœ¯æ ˆ

| ç»„ä»¶ | æ¨èæ–¹æ¡ˆ | æ›¿ä»£æ–¹æ¡ˆ | ç†ç”± |
|------|----------|----------|------|
| **RAGæ¡†æ¶** | LangChain | LlamaIndex | ç”Ÿæ€å®Œå–„ï¼Œç¤¾åŒºæ´»è·ƒ |
| **å‘é‡æ•°æ®åº“** | Qdrant | Pinecone, Weaviate, Chroma | å¼€æºï¼Œæ”¯æŒDockerï¼Œæ€§èƒ½å¥½ |
| **Embeddingæ¨¡å‹** | OpenAI text-embedding-3-small | sentence-transformers | æ€§ä»·æ¯”é«˜ï¼ŒAPIç®€å• |
| **LLM** | GPT-4o-mini | Claude-3.5-Sonnet, Qwen | æˆæœ¬ä½ï¼Œé€Ÿåº¦å¿«ï¼Œè´¨é‡é«˜ |
| **ä»»åŠ¡é˜Ÿåˆ—** | Celery + Redis | RQ | å¼‚æ­¥å¤„ç†é•¿ä»»åŠ¡ |
| **ç¼“å­˜å±‚** | Redis | Memcached | ç¼“å­˜æŸ¥è¯¢ç»“æœ |

### æ•°æ®åº“è®¾è®¡

```sql
-- RAG çŸ¥è¯†åº“è¡¨
CREATE TABLE knowledge_base (
    id INT AUTO_INCREMENT PRIMARY KEY,
    title VARCHAR(255) NOT NULL,
    content TEXT NOT NULL,
    content_type VARCHAR(50) NOT NULL,  -- report, manual, faq, policy
    source VARCHAR(255),
    metadata JSON,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    INDEX idx_content_type (content_type),
    INDEX idx_created_at (created_at)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- å‘é‡ç´¢å¼•æ˜ å°„è¡¨ï¼ˆå­˜å‚¨å‘é‡IDå’ŒçŸ¥è¯†åº“IDçš„æ˜ å°„ï¼‰
CREATE TABLE vector_mappings (
    id INT AUTO_INCREMENT PRIMARY KEY,
    knowledge_base_id INT NOT NULL,
    vector_id VARCHAR(255) NOT NULL,  -- Qdrantä¸­çš„å‘é‡ID
    chunk_index INT DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (knowledge_base_id) REFERENCES knowledge_base(id) ON DELETE CASCADE,
    INDEX idx_vector_id (vector_id),
    INDEX idx_knowledge_base_id (knowledge_base_id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- AI æŸ¥è¯¢å†å²è¡¨
CREATE TABLE ai_query_history (
    id INT AUTO_INCREMENT PRIMARY KEY,
    user_id INT NOT NULL,
    query TEXT NOT NULL,
    response TEXT,
    retrieved_chunks JSON,  -- æ£€ç´¢åˆ°çš„æ–‡æ¡£å—
    llm_model VARCHAR(50),
    execution_time_ms INT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id),
    INDEX idx_user_id (user_id),
    INDEX idx_created_at (created_at)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- è‡ªåŠ¨ç”ŸæˆæŠ¥å‘Šè¡¨
CREATE TABLE generated_reports (
    id INT AUTO_INCREMENT PRIMARY KEY,
    report_type VARCHAR(50) NOT NULL,  -- weekly, monthly, alert, custom
    title VARCHAR(255) NOT NULL,
    content TEXT NOT NULL,
    data_snapshot JSON,  -- ç”ŸæˆæŠ¥å‘Šæ—¶çš„æ•°æ®å¿«ç…§
    created_by INT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (created_by) REFERENCES users(id),
    INDEX idx_report_type (report_type),
    INDEX idx_created_at (created_at)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

---

## ğŸ”„ æ•°æ®æµç¨‹

### 1. çŸ¥è¯†åº“æ„å»ºæµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ•°æ®æº       â”‚
â”‚ - ä¸šåŠ¡æŠ¥å‘Š    â”‚
â”‚ - äº§å“æ‰‹å†Œ    â”‚
â”‚ - å†å²æ•°æ®    â”‚
â”‚ - FAQæ–‡æ¡£     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ–‡æ¡£è§£æå™¨    â”‚
â”‚ - PDFâ†’Text   â”‚
â”‚ - Excelâ†’JSON â”‚
â”‚ - HTMLâ†’Text  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ–‡æœ¬åˆ†å—      â”‚
â”‚ - æŒ‰æ®µè½åˆ†å‰²  â”‚
â”‚ - é‡å çª—å£    â”‚
â”‚ - ä¿ç•™å…ƒæ•°æ®  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Embedding     â”‚
â”‚ - æ‰¹é‡å‘é‡åŒ–  â”‚
â”‚ - ç»´åº¦: 1536  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å‘é‡å­˜å‚¨      â”‚
â”‚ - Qdrant DB  â”‚
â”‚ - ç´¢å¼•ä¼˜åŒ–    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. æŸ¥è¯¢å¤„ç†æµç¨‹

```
ç”¨æˆ·è¾“å…¥: "ä¸Šä¸ªæœˆå“ªä¸ªäº§å“åº“å­˜å‘¨è½¬ç‡æœ€ä½ï¼Ÿ"
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. æ„å›¾è¯†åˆ«                   â”‚
â”‚    ç±»å‹: æ•°æ®æŸ¥è¯¢             â”‚
â”‚    éœ€è¦: SQL + RAG            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. å‘é‡æ£€ç´¢                   â”‚
â”‚    Query Embedding            â”‚
â”‚    â†’ Qdrantç›¸ä¼¼åº¦æœç´¢         â”‚
â”‚    â†’ Top-Kæ–‡æ¡£ï¼ˆK=5ï¼‰         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. æ•°æ®åº“æŸ¥è¯¢                 â”‚
â”‚    LLMç”ŸæˆSQL:                â”‚
â”‚    SELECT p.name,             â”‚
â”‚      SUM(sales)/AVG(inv)      â”‚
â”‚    FROM ...                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. ä¸Šä¸‹æ–‡æ„å»º                 â”‚
â”‚    æ£€ç´¢ç»“æœ + SQLç»“æœ         â”‚
â”‚    + ä¸šåŠ¡è§„åˆ™ + å†å²ä¸Šä¸‹æ–‡     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. LLMç”Ÿæˆå›ç­”                â”‚
â”‚    Prompt:                    â”‚
â”‚    - System: ä½ æ˜¯æ•°æ®åˆ†æå¸ˆ   â”‚
â”‚    - Context: [æ£€ç´¢å†…å®¹]      â”‚
â”‚    - Question: [ç”¨æˆ·é—®é¢˜]     â”‚
â”‚    - Data: [SQLç»“æœ]          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. å›ç­”ä¼˜åŒ–                   â”‚
â”‚    - Markdownæ ¼å¼åŒ–           â”‚
â”‚    - æ·»åŠ å¯è§†åŒ–å»ºè®®           â”‚
â”‚    - ç›¸å…³é—®é¢˜æ¨è             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    è¿”å›ç»™ç”¨æˆ·
```

---

## ğŸ“… å®æ–½é˜¶æ®µ

### Phase 1: åŸºç¡€è®¾æ–½æ­å»º (2å‘¨)

**ç›®æ ‡**: å»ºç«‹RAGåŸºç¡€æ¡†æ¶

```python
# Week 1: ç¯å¢ƒå’Œä¾èµ–
src/Backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ embeddings.py       # EmbeddingæœåŠ¡
â”‚   â”‚   â”œâ”€â”€ vector_store.py     # å‘é‡æ•°æ®åº“æ¥å£
â”‚   â”‚   â”œâ”€â”€ llm_client.py       # LLM APIå®¢æˆ·ç«¯
â”‚   â”‚   â””â”€â”€ rag_pipeline.py     # RAGä¸»æµç¨‹
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ ai_service.py       # AIä¸šåŠ¡é€»è¾‘
â”‚   â””â”€â”€ api/v1/
â”‚       â””â”€â”€ ai.py               # AI APIç«¯ç‚¹
```

**ä»»åŠ¡æ¸…å•**:
- [x] å®‰è£…ä¾èµ–: `langchain`, `qdrant-client`, `openai`
- [x] é…ç½®Qdrant Dockerå®¹å™¨
- [x] å®ç°EmbeddingæœåŠ¡
- [x] åˆ›å»ºå‘é‡å­˜å‚¨æ¥å£
- [x] åŸºç¡€LLMè°ƒç”¨å°è£…

**Docker Composeé…ç½®**:
```yaml
services:
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_storage:/qdrant/storage
    environment:
      - QDRANT_ALLOW_RECOVERY_MODE=true

volumes:
  qdrant_storage:
```

### Phase 2: çŸ¥è¯†åº“å»ºè®¾ (2å‘¨)

**ç›®æ ‡**: å¯¼å…¥ä¸šåŠ¡çŸ¥è¯†å’Œå†å²æ•°æ®

**æ•°æ®æº**:
1. **ä¸šåŠ¡æ–‡æ¡£**
   - äº§å“æ‰‹å†Œï¼ˆPDFï¼‰
   - æ“ä½œæµç¨‹ï¼ˆMarkdownï¼‰
   - å¸¸è§é—®é¢˜ï¼ˆJSONï¼‰

2. **å†å²æ•°æ®**
   - è¿‡å»12ä¸ªæœˆé”€å”®æ•°æ®
   - åº“å­˜å˜åŒ–è®°å½•
   - ç»é”€å•†äº¤æ˜“å†å²

3. **åˆ†ææŠ¥å‘Š**
   - è‡ªåŠ¨ç”Ÿæˆå‘¨æŠ¥/æœˆæŠ¥æ¨¡æ¿
   - å†å²åˆ†æç»“æœ

**ä»£ç ç¤ºä¾‹**:
```python
# src/Backend/app/ai/knowledge_builder.py

from langchain.document_loaders import PDFLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Qdrant
from qdrant_client import QdrantClient

class KnowledgeBuilder:
    def __init__(self):
        self.client = QdrantClient(url="http://localhost:6333")
        self.collection_name = "warehouse_knowledge"

    async def build_from_documents(self, doc_paths: List[str]):
        """ä»æ–‡æ¡£æ„å»ºçŸ¥è¯†åº“"""
        documents = []

        # 1. åŠ è½½æ–‡æ¡£
        for path in doc_paths:
            if path.endswith('.pdf'):
                loader = PDFLoader(path)
            else:
                loader = TextLoader(path)
            documents.extend(loader.load())

        # 2. æ–‡æœ¬åˆ†å—
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", " ", ""]
        )
        chunks = text_splitter.split_documents(documents)

        # 3. å‘é‡åŒ–å¹¶å­˜å‚¨
        vectorstore = Qdrant(
            client=self.client,
            collection_name=self.collection_name,
            embeddings=self.get_embedding_function()
        )

        await vectorstore.aadd_documents(chunks)

        return len(chunks)

    async def build_from_database(self):
        """ä»æ•°æ®åº“æ„å»ºçŸ¥è¯†åº“"""
        # æŸ¥è¯¢å†å²é”€å”®ã€åº“å­˜ã€è®¢å•æ•°æ®
        # è½¬æ¢ä¸ºæ–‡æœ¬æè¿°
        # å‘é‡åŒ–å­˜å‚¨
        pass
```

### Phase 3: RAGæ ¸å¿ƒåŠŸèƒ½ (3å‘¨)

**ç›®æ ‡**: å®ç°å®Œæ•´çš„RAGæŸ¥è¯¢æµç¨‹

**æ ¸å¿ƒç»„ä»¶**:

```python
# src/Backend/app/ai/rag_pipeline.py

from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from qdrant_client import QdrantClient

class RAGPipeline:
    def __init__(self, config):
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.7,
            api_key=config.OPENAI_API_KEY
        )

        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small"
        )

        self.vector_store = self._init_vector_store()

    def _init_vector_store(self):
        """åˆå§‹åŒ–å‘é‡å­˜å‚¨"""
        client = QdrantClient(url="http://localhost:6333")
        from langchain_community.vectorstores import Qdrant

        return Qdrant(
            client=client,
            collection_name="warehouse_knowledge",
            embeddings=self.embeddings
        )

    async def query(self, question: str, user_context: dict = None):
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""

        # 1. æ„å›¾è¯†åˆ«
        intent = await self._classify_intent(question)

        # 2. å‘é‡æ£€ç´¢
        relevant_docs = await self.vector_store.asimilarity_search(
            question,
            k=5
        )

        # 3. æ•°æ®åº“æŸ¥è¯¢ï¼ˆå¦‚æœéœ€è¦ï¼‰
        db_results = None
        if intent.requires_data:
            db_results = await self._execute_sql_query(question)

        # 4. æ„å»ºä¸Šä¸‹æ–‡
        context = self._build_context(
            question=question,
            documents=relevant_docs,
            db_results=db_results,
            user_context=user_context
        )

        # 5. ç”Ÿæˆå›ç­”
        prompt = PromptTemplate(
            template="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»“åº“ç®¡ç†æ•°æ®åˆ†æå¸ˆã€‚

åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ï¼š

ç›¸å…³æ–‡æ¡£:
{documents}

æ•°æ®åº“æŸ¥è¯¢ç»“æœ:
{data}

ç”¨æˆ·é—®é¢˜: {question}

è¯·æä¾›è¯¦ç»†ã€å‡†ç¡®çš„åˆ†æï¼Œå¹¶ç»™å‡ºå¯æ‰§è¡Œçš„å»ºè®®ã€‚""",
            input_variables=["documents", "data", "question"]
        )

        chain = prompt | self.llm

        response = await chain.ainvoke({
            "documents": "\n".join([doc.page_content for doc in relevant_docs]),
            "data": str(db_results) if db_results else "æ— ",
            "question": question
        })

        return {
            "answer": response.content,
            "sources": [doc.metadata for doc in relevant_docs],
            "data": db_results
        }

    async def _classify_intent(self, question: str):
        """åˆ†ç±»ç”¨æˆ·æ„å›¾"""
        # ç®€å•å®ç°ï¼šä½¿ç”¨LLMåˆ†ç±»
        # ç±»å‹ï¼šæ•°æ®æŸ¥è¯¢ã€è¶‹åŠ¿åˆ†æã€å¼‚å¸¸æ£€æµ‹ã€æŠ¥å‘Šç”Ÿæˆ
        pass

    async def _execute_sql_query(self, question: str):
        """ç”Ÿæˆå¹¶æ‰§è¡ŒSQLæŸ¥è¯¢"""
        # ä½¿ç”¨LLMç”ŸæˆSQL
        # éªŒè¯å®‰å…¨æ€§
        # æ‰§è¡ŒæŸ¥è¯¢
        pass
```

### Phase 4: æŠ¥å‘Šç”Ÿæˆ (2å‘¨)

**ç›®æ ‡**: è‡ªåŠ¨ç”Ÿæˆä¸šåŠ¡æŠ¥å‘Š

**æŠ¥å‘Šç±»å‹**:
1. **å‘¨æŠ¥**: é”€å”®æ±‡æ€»ã€åº“å­˜å˜åŒ–ã€å¼‚å¸¸è­¦æŠ¥
2. **æœˆæŠ¥**: è¶‹åŠ¿åˆ†æã€KPIè¾¾æˆã€æ”¹è¿›å»ºè®®
3. **ä¸“é¡¹æŠ¥å‘Š**: äº§å“åˆ†æã€ç»é”€å•†åˆ†æã€åº“å­˜ä¼˜åŒ–

```python
# src/Backend/app/ai/report_generator.py

class ReportGenerator:
    async def generate_weekly_report(self, week_start: date):
        """ç”Ÿæˆå‘¨æŠ¥"""

        # 1. æ”¶é›†æ•°æ®
        data = await self._collect_weekly_data(week_start)

        # 2. RAGåˆ†æ
        insights = await self.rag.analyze_trends(data)

        # 3. ç”ŸæˆæŠ¥å‘Š
        prompt = """åŸºäºä»¥ä¸‹æ•°æ®ç”Ÿæˆæœ¬å‘¨ä¸šåŠ¡æŠ¥å‘Šï¼š

é”€å”®æ•°æ®: {sales}
åº“å­˜æ•°æ®: {inventory}
å¼‚å¸¸äº‹ä»¶: {alerts}
å†å²å¯¹æ¯”: {comparison}

è¯·ç”ŸæˆåŒ…å«ä»¥ä¸‹éƒ¨åˆ†çš„MarkdownæŠ¥å‘Šï¼š
1. æ‰§è¡Œæ‘˜è¦
2. å…³é”®æŒ‡æ ‡
3. è¶‹åŠ¿åˆ†æ
4. å¼‚å¸¸è­¦æŠ¥
5. æ”¹è¿›å»ºè®®"""

        report = await self.llm.ainvoke(prompt.format(**data))

        # 4. ä¿å­˜æŠ¥å‘Š
        await self._save_report(report, "weekly", week_start)

        return report
```

### Phase 5: å‰ç«¯é›†æˆ (2å‘¨)

**ç›®æ ‡**: æä¾›ç”¨æˆ·ç•Œé¢

**é¡µé¢è®¾è®¡**:

```typescript
// src/pages/AIAssistant.tsx

const AIAssistant: React.FC = () => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [input, setInput] = useState('');
  const [loading, setLoading] = useState(false);

  const handleSend = async () => {
    setLoading(true);

    const response = await apiService.aiQuery({
      question: input,
      context: {
        user_id: currentUser.id,
        history: messages.slice(-5)
      }
    });

    setMessages([
      ...messages,
      { role: 'user', content: input },
      { role: 'assistant', content: response.answer, sources: response.sources }
    ]);

    setLoading(false);
  };

  return (
    <div className="ai-assistant">
      <ChatMessages messages={messages} />
      <ChatInput value={input} onChange={setInput} onSend={handleSend} />
      <QuickActions />  {/* å¿«æ·é—®é¢˜ */}
    </div>
  );
};
```

**å¿«æ·æŸ¥è¯¢æ¨¡æ¿**:
- "ç”Ÿæˆæœ¬å‘¨åº“å­˜æŠ¥å‘Š"
- "åˆ†æé”€å”®ä¸‹é™åŸå› "
- "å“ªäº›äº§å“éœ€è¦è¡¥è´§ï¼Ÿ"
- "å¯¹æ¯”A/Bç»é”€å•†è¡¨ç°"

### Phase 6: ä¼˜åŒ–å’Œç›‘æ§ (æŒç»­)

**ä¼˜åŒ–æ–¹å‘**:
1. **æ€§èƒ½ä¼˜åŒ–**
   - æŸ¥è¯¢ç»“æœç¼“å­˜
   - å‘é‡æ£€ç´¢åŠ é€Ÿ
   - æ‰¹é‡å¤„ç†

2. **è´¨é‡ä¼˜åŒ–**
   - Promptå·¥ç¨‹
   - Few-shotç¤ºä¾‹
   - ç­”æ¡ˆéªŒè¯

3. **æˆæœ¬ä¼˜åŒ–**
   - æ™ºèƒ½è·¯ç”±ï¼ˆç®€å•é—®é¢˜ç”¨å°æ¨¡å‹ï¼‰
   - Tokenè®¡æ•°å’Œé™åˆ¶
   - ç¼“å­˜ç­–ç•¥

**ç›‘æ§æŒ‡æ ‡**:
```python
# src/Backend/app/ai/metrics.py

class AIMetrics:
    """AIæœåŠ¡ç›‘æ§"""

    metrics = {
        "query_count": Counter,
        "avg_response_time": Histogram,
        "llm_token_usage": Counter,
        "vector_search_time": Histogram,
        "cache_hit_rate": Gauge
    }
```

---

## ğŸš€ éƒ¨ç½²æ–¹æ¡ˆ

### Docker Compose å®Œæ•´é…ç½®

```yaml
version: '3.8'

services:
  # ç°æœ‰æœåŠ¡
  backend:
    # ... ç°æœ‰é…ç½®
    depends_on:
      - qdrant
      - redis
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - QDRANT_URL=http://qdrant:6333

  # å‘é‡æ•°æ®åº“
  qdrant:
    image: qdrant/qdrant:v1.8.0
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    environment:
      - QDRANT_ALLOW_RECOVERY_MODE=true

  # Redis (ç”¨äºç¼“å­˜å’Œä»»åŠ¡é˜Ÿåˆ—)
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  # Celery Worker (å¼‚æ­¥ä»»åŠ¡)
  celery_worker:
    build: ./src/Backend
    command: celery -A app.workers worker -l info
    depends_on:
      - redis
      - backend
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0

  # Celery Beat (å®šæ—¶ä»»åŠ¡)
  celery_beat:
    build: ./src/Backend
    command: celery -A app.workers beat -l info
    depends_on:
      - redis
      - celery_worker

volumes:
  qdrant_data:
  redis_data:
```

---

## ğŸ’° æˆæœ¬ä¼°ç®—

### å¼€å‘æˆæœ¬

| é˜¶æ®µ | å·¥æ—¶ | è¯´æ˜ |
|------|------|------|
| Phase 1 | 80h | åŸºç¡€è®¾æ–½ |
| Phase 2 | 80h | çŸ¥è¯†åº“ |
| Phase 3 | 120h | RAGæ ¸å¿ƒ |
| Phase 4 | 80h | æŠ¥å‘Šç”Ÿæˆ |
| Phase 5 | 80h | å‰ç«¯é›†æˆ |
| Phase 6 | 40h/æœˆ | æŒç»­ä¼˜åŒ– |

**æ€»è®¡**: ~520å°æ—¶ï¼ˆçº¦3ä¸ªæœˆï¼‰

### è¿è¥æˆæœ¬ï¼ˆæœˆåº¦ï¼‰

| é¡¹ç›® | æˆæœ¬ | è¯´æ˜ |
|------|------|------|
| **OpenAI API** | $50-200 | 1M tokens â‰ˆ $0.10-0.60 |
| **æœåŠ¡å™¨** | $50-100 | 4C8Gäº‘æœåŠ¡å™¨ |
| **Qdrant** | $0 | è‡ªæ‰˜ç®¡ |
| **Redis** | $0 | è‡ªæ‰˜ç®¡ |
| **æ€»è®¡** | **$100-300** | å–å†³äºä½¿ç”¨é‡ |

### æˆæœ¬ä¼˜åŒ–å»ºè®®

1. **ä½¿ç”¨æœ¬åœ°Embeddingæ¨¡å‹**
   - èŠ‚çœ70%+ Embeddingæˆæœ¬
   - æ¨¡å‹: `sentence-transformers/all-MiniLM-L6-v2`

2. **æ™ºèƒ½è·¯ç”±**
   ```python
   def route_query(question: str):
       complexity = analyze_complexity(question)

       if complexity == "simple":
           return "gpt-4o-mini"  # $0.15/1M tokens
       elif complexity == "medium":
           return "gpt-4o"        # $2.50/1M tokens
       else:
           return "o1-preview"    # $15/1M tokens
   ```

3. **ç¼“å­˜ç­–ç•¥**
   - ç›¸ä¼¼é—®é¢˜ç¼“å­˜ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ > 0.95ï¼‰
   - æ•°æ®åº“æŸ¥è¯¢ç»“æœç¼“å­˜
   - æŠ¥å‘Šæ¨¡æ¿ç¼“å­˜

---

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

### ç›®æ ‡KPI

| æŒ‡æ ‡ | ç›®æ ‡å€¼ | æµ‹é‡æ–¹æ³• |
|------|--------|----------|
| æŸ¥è¯¢å“åº”æ—¶é—´ | < 3ç§’ | P95 |
| ç­”æ¡ˆå‡†ç¡®ç‡ | > 90% | äººå·¥è¯„ä¼° |
| å‘é‡æ£€ç´¢æ—¶é—´ | < 100ms | P99 |
| ç¼“å­˜å‘½ä¸­ç‡ | > 60% | Redis metrics |
| å¯ç”¨æ€§ | 99.5% | Uptime monitoring |

---

## ğŸ” å®‰å…¨è€ƒè™‘

### æ•°æ®å®‰å…¨

1. **SQLæ³¨å…¥é˜²æŠ¤**
   ```python
   def validate_generated_sql(sql: str) -> bool:
       """éªŒè¯LLMç”Ÿæˆçš„SQL"""
       # åªå…è®¸SELECTæŸ¥è¯¢
       if not sql.strip().upper().startswith("SELECT"):
           return False

       # ç¦æ­¢å±é™©å…³é”®å­—
       dangerous = ["DROP", "DELETE", "UPDATE", "INSERT", "ALTER"]
       if any(kw in sql.upper() for kw in dangerous):
           return False

       return True
   ```

2. **æƒé™æ§åˆ¶**
   - ç”¨æˆ·åªèƒ½æŸ¥è¯¢è‡ªå·±æƒé™èŒƒå›´å†…çš„æ•°æ®
   - æ•æ„Ÿä¿¡æ¯è„±æ•

3. **APIé™æµ**
   ```python
   from slowapi import Limiter

   limiter = Limiter(key_func=get_remote_address)

   @app.post("/api/v1/ai/query")
   @limiter.limit("10/minute")
   async def ai_query(request: QueryRequest):
       ...
   ```

---

## ğŸ“ˆ æœªæ¥æ‰©å±•

### é˜¶æ®µæ€§å¢å¼º

1. **å¤šæ¨¡æ€æ”¯æŒ** (6ä¸ªæœˆå)
   - å›¾è¡¨è¯†åˆ«å’Œåˆ†æ
   - è¯­éŸ³è¾“å…¥/è¾“å‡º

2. **é¢„æµ‹åˆ†æ** (9ä¸ªæœˆå)
   - é”€å”®é¢„æµ‹
   - åº“å­˜ä¼˜åŒ–å»ºè®®
   - å¼‚å¸¸é¢„è­¦

3. **å¤šè¯­è¨€æ”¯æŒ** (12ä¸ªæœˆå)
   - ä¸­è‹±æ–‡åŒè¯­
   - è‡ªåŠ¨ç¿»è¯‘

4. **Agentç³»ç»Ÿ** (18ä¸ªæœˆå)
   - è‡ªä¸»æ‰§è¡Œä»»åŠ¡
   - å¤šæ­¥éª¤æ¨ç†
   - å·¥å…·è°ƒç”¨

---

## ğŸ“š å‚è€ƒèµ„æº

### å­¦ä¹ èµ„æ–™

- [LangChain Documentation](https://python.langchain.com/)
- [Qdrant Documentation](https://qdrant.tech/documentation/)
- [OpenAI API Reference](https://platform.openai.com/docs)

### å¼€æºé¡¹ç›®

- [Quivr](https://github.com/QuivrHQ/quivr) - RAGåº”ç”¨å‚è€ƒ
- [Danswer](https://github.com/danswer-ai/danswer) - ä¼ä¸šæœç´¢
- [ChatFiles](https://github.com/guangzhengli/ChatFiles) - æ–‡æ¡£é—®ç­”

---

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### æœ€å°å¯è¡Œäº§å“ (MVP)

**1å‘¨å¿«é€ŸéªŒè¯** - åªå®ç°æ ¸å¿ƒåŠŸèƒ½ï¼š

```bash
# 1. å®‰è£…ä¾èµ–
pip install langchain openai qdrant-client

# 2. å¯åŠ¨Qdrant
docker run -p 6333:6333 qdrant/qdrant

# 3. åˆ›å»ºç®€å•RAG
python scripts/simple_rag.py

# 4. æµ‹è¯•æŸ¥è¯¢
curl -X POST http://localhost:8000/api/v1/ai/query \
  -H "Content-Type: application/json" \
  -d '{"question": "æœ¬æœˆé”€å”®é¢æ˜¯å¤šå°‘ï¼Ÿ"}'
```

**simple_rag.py**:
```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Qdrant
from qdrant_client import QdrantClient

# åˆå§‹åŒ–
llm = ChatOpenAI(model="gpt-4o-mini")
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

client = QdrantClient(url="http://localhost:6333")
vectorstore = Qdrant(client, "test", embeddings)

# æ·»åŠ ç¤ºä¾‹çŸ¥è¯†
docs = ["2024å¹´10æœˆé”€å”®é¢: $125,000", "åº“å­˜å‘¨è½¬ç‡: 4.5æ¬¡/æœˆ"]
vectorstore.add_texts(docs)

# æŸ¥è¯¢
def query(question: str):
    # æ£€ç´¢
    docs = vectorstore.similarity_search(question, k=2)
    context = "\n".join([d.page_content for d in docs])

    # ç”Ÿæˆ
    response = llm.invoke(f"Context: {context}\n\nQuestion: {question}")
    return response.content

print(query("æœ¬æœˆé”€å”®é¢æ˜¯å¤šå°‘ï¼Ÿ"))
```

---

## ğŸ“ æ”¯æŒä¸åé¦ˆ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·è”ç³»å¼€å‘å›¢é˜Ÿæˆ–æäº¤Issueã€‚

---

**ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-11-13
**ä½œè€…**: Claude Code AI Assistant
